{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration for APD Verification\n",
    "\n",
    "This notebook explores the three datasets used for experiments:\n",
    "- CIFAR-10\n",
    "- Fashion-MNIST\n",
    "- SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import get_cifar10_loaders, get_fashion_mnist_loaders, get_svhn_loaders, get_dataset_info\n",
    "from utils.visualization import plot_class_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10\n",
    "train_loader, test_loader, class_names = get_cifar10_loaders(batch_size=64)\n",
    "dataset_info = get_dataset_info('cifar10')\n",
    "\n",
    "print(\"CIFAR-10 Dataset Information:\")\n",
    "print(f\"Number of classes: {dataset_info['num_classes']}\")\n",
    "print(f\"Class names: {dataset_info['classes']}\")\n",
    "print(f\"Input shape: {dataset_info['input_shape']}\")\n",
    "print(f\"Training samples: {dataset_info['num_train']}\")\n",
    "print(f\"Test samples: {dataset_info['num_test']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images from CIFAR-10\n",
    "def show_samples(loader, class_names, num_samples=8, title=\"Sample Images\"):\n",
    "    dataiter = iter(loader)\n",
    "    images, labels = next(dataiter)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, num_samples//2, figsize=(12, 6))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Denormalize CIFAR-10 images\n",
    "    mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        img = images[i] * std + mean\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        \n",
    "        axes[i].imshow(img.permute(1, 2, 0))\n",
    "        axes[i].set_title(f'{class_names[labels[i]]}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_samples(train_loader, class_names, num_samples=8, title=\"CIFAR-10 Sample Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show class distribution\n",
    "plot_class_distribution(train_loader, \"CIFAR-10\", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion-MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fashion-MNIST\n",
    "train_loader_fashion, test_loader_fashion, class_names_fashion = get_fashion_mnist_loaders(batch_size=64)\n",
    "dataset_info_fashion = get_dataset_info('fashion_mnist')\n",
    "\n",
    "print(\"Fashion-MNIST Dataset Information:\")\n",
    "print(f\"Number of classes: {dataset_info_fashion['num_classes']}\")\n",
    "print(f\"Class names: {dataset_info_fashion['classes']}\")\n",
    "print(f\"Input shape: {dataset_info_fashion['input_shape']}\")\n",
    "print(f\"Training samples: {dataset_info_fashion['num_train']}\")\n",
    "print(f\"Test samples: {dataset_info_fashion['num_test']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images from Fashion-MNIST\n",
    "def show_fashion_samples(loader, class_names, num_samples=8):\n",
    "    dataiter = iter(loader)\n",
    "    images, labels = next(dataiter)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, num_samples//2, figsize=(12, 6))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Denormalize\n",
    "        img = images[i] * 0.5 + 0.5\n",
    "        \n",
    "        axes[i].imshow(img.squeeze(), cmap='gray')\n",
    "        axes[i].set_title(f'{class_names[labels[i]]}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(\"Fashion-MNIST Sample Images\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_fashion_samples(train_loader_fashion, class_names_fashion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVHN Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SVHN\n",
    "train_loader_svhn, test_loader_svhn, class_names_svhn = get_svhn_loaders(batch_size=64)\n",
    "dataset_info_svhn = get_dataset_info('svhn')\n",
    "\n",
    "print(\"SVHN Dataset Information:\")\n",
    "print(f\"Number of classes: {dataset_info_svhn['num_classes']}\")\n",
    "print(f\"Class names: {dataset_info_svhn['classes']}\")\n",
    "print(f\"Input shape: {dataset_info_svhn['input_shape']}\")\n",
    "print(f\"Training samples: {dataset_info_svhn['num_train']}\")\n",
    "print(f\"Test samples: {dataset_info_svhn['num_test']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display SVHN samples\n",
    "def show_svhn_samples(loader, class_names, num_samples=8):\n",
    "    dataiter = iter(loader)\n",
    "    images, labels = next(dataiter)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, num_samples//2, figsize=(12, 6))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Denormalize\n",
    "        img = images[i] * 0.5 + 0.5\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        \n",
    "        axes[i].imshow(img.permute(1, 2, 0))\n",
    "        axes[i].set_title(f'Digit: {class_names[labels[i]]}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(\"SVHN Sample Images\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_svhn_samples(train_loader_svhn, class_names_svhn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show effect of data augmentation on CIFAR-10\n",
    "def show_augmentation_effects(loader, idx=0):\n",
    "    \"\"\"Show the same image with different augmentations.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Get multiple augmented versions of similar images\n",
    "    for i in range(8):\n",
    "        images, labels = next(iter(loader))\n",
    "        \n",
    "        # Denormalize\n",
    "        mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)\n",
    "        img = images[idx] * std + mean\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        \n",
    "        axes[i].imshow(img.permute(1, 2, 0))\n",
    "        axes[i].set_title(f'Aug {i+1}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(\"Data Augmentation Effects (Random Crop + Horizontal Flip)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Note: Each image shows a different random augmentation of similar samples\")\n",
    "show_augmentation_effects(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify batch shapes and statistics\n",
    "def check_batch_stats(loader, dataset_name):\n",
    "    images, labels = next(iter(loader))\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Batch Statistics:\")\n",
    "    print(f\"Batch shape: {images.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Image data type: {images.dtype}\")\n",
    "    print(f\"Label data type: {labels.dtype}\")\n",
    "    print(f\"Image value range: [{images.min():.3f}, {images.max():.3f}]\")\n",
    "    print(f\"Unique labels in batch: {torch.unique(labels).tolist()}\")\n",
    "    print(f\"Mean: {images.mean():.3f}, Std: {images.std():.3f}\")\n",
    "\n",
    "check_batch_stats(train_loader, \"CIFAR-10\")\n",
    "check_batch_stats(train_loader_fashion, \"Fashion-MNIST\")\n",
    "check_batch_stats(train_loader_svhn, \"SVHN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has explored the three datasets that will be used for APD verification:\n",
    "\n",
    "1. **CIFAR-10**: 32x32 RGB images of 10 object categories\n",
    "2. **Fashion-MNIST**: 28x28 grayscale images of 10 fashion items\n",
    "3. **SVHN**: 32x32 RGB images of house number digits\n",
    "\n",
    "Key observations:\n",
    "- All datasets have 10 classes but different image properties\n",
    "- CIFAR-10 and SVHN use RGB images while Fashion-MNIST is grayscale\n",
    "- Data augmentation (random crop and horizontal flip) is applied to CIFAR-10 training\n",
    "- All images are normalized for better training stability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}